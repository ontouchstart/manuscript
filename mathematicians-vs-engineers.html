<!-- ======================================================================= --> 
<html>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    Mathematicians vs Engineers
  </title>
  <body>
    <p>
      "Von Neumann's approach was to bring a handful of engineers into a
      den of mathematicians, rather than a handful of mathematicians into
      a den of engineers. This freed the project from any constraints
      that might have been imposed by an established group of engineers
      with preexisting opinions as to how a computer should be built."
    </p>
    <p align="right">
      &mdash; Georgy Dyson, "Turing's Cathedral".
    </p>
    <p>
      "The MANIAC’s logical architecture was indisputably the work of
      Burks, Goldstine, and von Neumann, whatever their ideas’ original
      source. Its physical implementation was indisputably the work of
      Bigelow, and its electronic design was largely the result of teamwork
      between Bigelow, Pomerene, Rosenberg, Slutz, and Ware."
    </p>
    <p>
      "You could never tell whether he was doing it because he was seeking
      perfection or because he was worried about reliability."
    </p>
    <p>
      These are great view points from different perspectives.
    </p>
    <p>
      Think about a piece of code in some programming language, we can
      do static analysis to find logic issues as a mathematican.  But we
      can also debug it at runtime as an engineer.
    </p>
    <p>
      One thing mathematicians can't control is the runtime environment,
      which can't be captured by the code itself.  The best we can do is
      to validate the code and data schema. That is what linter and
      compiler do.
    </p>
    <p>
      One thing engineers have difficulty to identify at the runtime is
      the fundamental logic of the code, we can't TDD us out of it unless
      we understand what is going on.
    </p>
    <p>
    <p>
      With modern software frameworks, stacks of dependencies and machine
      (AI) generated artifacts, both constraints get amplified exponentially.
      It becomes harder and harder to find root causes of issues and
      easier and easier to introduce problematic code paths that are hard
      to detect by both static analysis and runtime testing.
    </p>
    <p>
      These challenges require the combination of mathematical and engeering
      mindsets or some new mindset.
    </p>
    <p>
      We can't GenAI ourselve out of this.
    </p>
    <p>
      There is another view which is closer to what physicists might take,
      i.e., use computer for discovery and simulation. The goal is not
      to prove something or build some product that need to be validated
      and maintained.
    </p>
    <p>
      Modern systems programming languages like Rust and client/server
      based stateless computation runtime, CI/CD, unit testing and e2e
      testing will give us fantastic tools to create new abstractions and
      runtime environments to simulate new abstract worlds. For example,
      neural networks and large language models give us rich worlds to
      explore and simulate the real world.
    </p>
    <p>
      "Go ahead, nothing else matters, get it running at this speed and
      this capability, and the rest of it is just a lot of nonsense."
    </p>
  </body>
</html>
<!-- ======================================================================= --> 
